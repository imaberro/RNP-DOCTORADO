{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Tarea Redes Neuronales Profundas - Marcelo Becerra.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg_UNV7Y3IPi"
      },
      "source": [
        "# Implementando Arquitectura VGG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Hyzh2gz3Rzj"
      },
      "source": [
        "Se importa un repositorio en github asociado a Marcelo Becerra Rozas de RUT: 19.339.344-6 alumno del ramo de Redes Neuronales Profundas. El objetivo de esto es, para facilidad de uso de los dataSets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdOmgAYBtmDT",
        "outputId": "3516fc12-3d35-41ba-ae8e-ac34c87fc8eb"
      },
      "source": [
        "!git clone https://github.com/imaberro/RNP-DOCTORADO.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'RNP-DOCTORADO'...\n",
            "remote: Enumerating objects: 1131, done.\u001b[K\n",
            "remote: Counting objects: 100% (1131/1131), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1115/1115), done.\u001b[K\n",
            "remote: Total 122108 (delta 9), reused 1130 (delta 8), pack-reused 120977\u001b[K\n",
            "Receiving objects: 100% (122108/122108), 215.44 MiB | 33.36 MiB/s, done.\n",
            "Resolving deltas: 100% (1117/1117), done.\n",
            "Checking out files: 100% (132650/132650), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ctKN2Cstory",
        "outputId": "a7b7dc39-b975-4b93-be65-e1a10bc530fe"
      },
      "source": [
        "\n",
        "# Librerías de Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras import regularizers\n",
        "from keras.layers import ZeroPadding2D\n",
        "\n",
        "from keras.callbacks import CSVLogger\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 2572095732786004127\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14638920512\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 4767795275520533247\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpx1TYWhuEby"
      },
      "source": [
        "# Inicializamos la red convolucional\n",
        "classifier = Sequential()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBMlZkxruwo7"
      },
      "source": [
        "La arquitectura que se está implementando en esta primera instancia es la conocida como VGG.\r\n",
        "\r\n",
        "Se tienen consideradas tres layers convolucionales de kernel 2x2, 2x1 y 1x2 respectivamente de 32 pixeles cada una y con un input o imágenes de 64x64 píxeles RGB para el primer layer. Cada layer contempla activación de tipo ReLu\r\n",
        "\r\n",
        "Por cada layer se realiza una normalización, luego de las tres layers, se realiza un MaxPooling de tamaño 2x2.\r\n",
        "\r\n",
        "Los siguientes tres layers tienen 48 pixeles con un kernel de 2x2. Nuevamente por cada layer se realizará un normalización de la salida. Y finalmente, otra vez un MaxPooling de 2x2.\r\n",
        "\r\n",
        "Los siguientes layers (Siempre separandolos de 3 en 3) están contemplados con tamaños de 64, 80 y 96 píxeles con un kernel de 2x2 y MaxPooling de 2x2 también.\r\n",
        "\r\n",
        "Finalmente tenemos 2 capas Dense de tamaño 800 con activación 800 y finalmente la última de tamaño 200 y activación de tipo Softmax.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC6XocnYuFtt"
      },
      "source": [
        "#Convoluciones\n",
        "classifier.add(Conv2D(32, (2, 2), input_shape = (64, 64, 3), activation = 'relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "classifier.add(Conv2D(32, (2, 1), activation = 'relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "classifier.add(Conv2D(32, (1, 2), activation = 'relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "# Agregamos más layers convolucionales\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "classifier.add(Conv2D(48, (2, 2), activation = 'relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "classifier.add(Conv2D(48, (2, 2), activation = 'relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "classifier.add(Conv2D(48, (2, 2), activation = 'relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "# Agregamos más layers convolucionales\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "classifier.add(Conv2D(64, (2, 2), activation = 'relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "classifier.add(Conv2D(64, (2, 2), activation = 'relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "classifier.add(Conv2D(64, (2, 2), activation = 'relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "# Agregamos más layers convolucionales\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "classifier.add(Conv2D(80, (2, 2), activation = 'relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "classifier.add(Conv2D(80, (2, 2), activation = 'relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "classifier.add(Conv2D(80, (2, 2), activation = 'relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "# Agregamos más layers convolucionales\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "classifier.add(ZeroPadding2D((1,1)))\n",
        "classifier.add(Conv2D(96, (2, 2), activation = 'relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "classifier.add(ZeroPadding2D((1,1)))\n",
        "classifier.add(Conv2D(96, (2, 2), activation = 'relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "classifier.add(ZeroPadding2D((1,1)))\n",
        "classifier.add(Conv2D(96, (2, 2), activation = 'relu'))\n",
        "classifier.add(BatchNormalization())\n",
        "\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "classifier.add(Flatten())\n",
        "\n",
        "classifier.add(Dense(units = 800, activation = 'relu', kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(0.00001)))\n",
        "classifier.add(Dense(units = 800, activation = 'relu', kernel_initializer='glorot_uniform', kernel_regularizer=regularizers.l2(0.00001)))\n",
        "classifier.add(Dense(units = 200, activation = 'softmax'))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4_spnweuOi9",
        "outputId": "1d21cf4e-f887-4506-f7ec-615ec2ef32e8"
      },
      "source": [
        "# Compilamos la red\n",
        "\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "learning_rate = 1e-4\n",
        "lr = 0.001\n",
        "def updateLR(epoch, lr):\n",
        "    if(epoch % 10 == 0 and epoch !=0):\n",
        "        lr *= 0.5\n",
        "        print(\"update\",lr)\n",
        "    return lr\n",
        "\n",
        "lrate = LearningRateScheduler(updateLR)\n",
        "\n",
        "Adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.00014, amsgrad=False)\n",
        "classifier.compile(optimizer = Adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "classifier.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 63, 63, 32)        416       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 63, 63, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 62, 63, 32)        2080      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 62, 63, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 62, 62, 32)        2080      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 62, 62, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 31, 31, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 30, 30, 48)        6192      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 30, 30, 48)        192       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 29, 29, 48)        9264      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 29, 29, 48)        192       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 28, 28, 48)        9264      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 28, 28, 48)        192       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 48)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 13, 13, 64)        12352     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 13, 13, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 12, 12, 64)        16448     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 12, 12, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 11, 11, 64)        16448     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 11, 11, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 4, 4, 80)          20560     \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 4, 4, 80)          320       \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 3, 3, 80)          25680     \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 3, 3, 80)          320       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 2, 2, 80)          25680     \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 2, 2, 80)          320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 80)          0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2 (None, 3, 3, 80)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 2, 2, 96)          30816     \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 2, 2, 96)          384       \n",
            "_________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPaddin (None, 4, 4, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 3, 3, 96)          36960     \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 3, 3, 96)          384       \n",
            "_________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPaddin (None, 5, 5, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 4, 4, 96)          36960     \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 4, 4, 96)          384       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 96)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 384)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 800)               308000    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 800)               640800    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 200)               160200    \n",
            "=================================================================\n",
            "Total params: 1,364,040\n",
            "Trainable params: 1,362,120\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBgfQSm801FT"
      },
      "source": [
        "Para los ajustes de las imágenes y de la red, se optó por algunas opciones definidas por ImageDataGenerator, el primero un reescalado, shear y zoom con rango de 0,2, un flip de tipo horizontal, una rotación de imágen de 90°, cambios de tamaños de imágenes tanto horizontal como vertical y finalmente un aumento de brillo de rangos entre 0,2 y 0,8.\r\n",
        "\r\n",
        "Un Batchsize de 23 y para cada imágen contenida del Dataset será estandarizada con un tamaño de 64x64 píxeles. Analizando un total de 100.000 imágenes dividas en 200 tipos de clases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaD2Ajwcucu4",
        "outputId": "0c67d6ed-03fb-4656-8306-5f90d3b3e28c"
      },
      "source": [
        "# Ajustamos la red a las imágenes\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True,\n",
        "                                   rotation_range=90,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   brightness_range=(0.2, 0.8)\n",
        "                                   )\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/RNP-DOCTORADO/DataImages/train',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 23,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/content/RNP-DOCTORADO/DataImages/validation',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 23,\n",
        "                                            class_mode = 'categorical')\n",
        "\n",
        "print(training_set)\n",
        "\n",
        "csv_logger = CSVLogger('training.log')\n",
        "\n",
        "history = classifier.fit(training_set,\n",
        "                         epochs = 30,\n",
        "                         validation_data = test_set,\n",
        "                         verbose=1)\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n",
            "<tensorflow.python.keras.preprocessing.image.DirectoryIterator object at 0x7fb5602d37f0>\n",
            "Epoch 1/30\n",
            "4348/4348 [==============================] - 207s 46ms/step - loss: 5.1590 - accuracy: 0.0168 - val_loss: 5.4057 - val_accuracy: 0.0217\n",
            "Epoch 2/30\n",
            "4348/4348 [==============================] - 196s 45ms/step - loss: 4.7781 - accuracy: 0.0384 - val_loss: 4.8052 - val_accuracy: 0.0454\n",
            "Epoch 3/30\n",
            "4348/4348 [==============================] - 196s 45ms/step - loss: 4.5899 - accuracy: 0.0560 - val_loss: 4.7534 - val_accuracy: 0.0495\n",
            "Epoch 4/30\n",
            "4348/4348 [==============================] - 195s 45ms/step - loss: 4.4775 - accuracy: 0.0680 - val_loss: 4.6233 - val_accuracy: 0.0594\n",
            "Epoch 5/30\n",
            "4348/4348 [==============================] - 195s 45ms/step - loss: 4.3838 - accuracy: 0.0774 - val_loss: 4.6748 - val_accuracy: 0.0640\n",
            "Epoch 6/30\n",
            "4348/4348 [==============================] - 194s 45ms/step - loss: 4.3003 - accuracy: 0.0911 - val_loss: 4.3241 - val_accuracy: 0.0862\n",
            "Epoch 7/30\n",
            "4348/4348 [==============================] - 195s 45ms/step - loss: 4.2434 - accuracy: 0.0967 - val_loss: 4.3055 - val_accuracy: 0.0958\n",
            "Epoch 8/30\n",
            "4348/4348 [==============================] - 196s 45ms/step - loss: 4.1921 - accuracy: 0.1034 - val_loss: 4.4611 - val_accuracy: 0.0819\n",
            "Epoch 9/30\n",
            "4348/4348 [==============================] - 195s 45ms/step - loss: 4.1554 - accuracy: 0.1081 - val_loss: 4.2305 - val_accuracy: 0.1005\n",
            "Epoch 10/30\n",
            "4348/4348 [==============================] - 194s 45ms/step - loss: 4.1151 - accuracy: 0.1136 - val_loss: 4.3111 - val_accuracy: 0.0983\n",
            "Epoch 11/30\n",
            "4348/4348 [==============================] - 195s 45ms/step - loss: 4.0785 - accuracy: 0.1196 - val_loss: 4.1897 - val_accuracy: 0.1065\n",
            "Epoch 12/30\n",
            "4348/4348 [==============================] - 194s 45ms/step - loss: 4.0615 - accuracy: 0.1210 - val_loss: 4.4114 - val_accuracy: 0.0975\n",
            "Epoch 13/30\n",
            "4348/4348 [==============================] - 195s 45ms/step - loss: 4.0247 - accuracy: 0.1264 - val_loss: 4.0780 - val_accuracy: 0.1171\n",
            "Epoch 14/30\n",
            "4348/4348 [==============================] - 195s 45ms/step - loss: 4.0006 - accuracy: 0.1306 - val_loss: 4.1576 - val_accuracy: 0.1128\n",
            "Epoch 15/30\n",
            "4348/4348 [==============================] - 195s 45ms/step - loss: 3.9920 - accuracy: 0.1317 - val_loss: 4.1564 - val_accuracy: 0.1129\n",
            "Epoch 16/30\n",
            "4348/4348 [==============================] - 194s 45ms/step - loss: 3.9700 - accuracy: 0.1343 - val_loss: 4.1560 - val_accuracy: 0.1159\n",
            "Epoch 17/30\n",
            "4348/4348 [==============================] - 194s 45ms/step - loss: 3.9466 - accuracy: 0.1379 - val_loss: 4.1940 - val_accuracy: 0.1105\n",
            "Epoch 18/30\n",
            "4348/4348 [==============================] - 195s 45ms/step - loss: 3.9323 - accuracy: 0.1394 - val_loss: 4.0298 - val_accuracy: 0.1241\n",
            "Epoch 19/30\n",
            "4348/4348 [==============================] - 195s 45ms/step - loss: 3.9140 - accuracy: 0.1426 - val_loss: 4.0979 - val_accuracy: 0.1223\n",
            "Epoch 20/30\n",
            "4348/4348 [==============================] - 196s 45ms/step - loss: 3.8989 - accuracy: 0.1443 - val_loss: 4.0282 - val_accuracy: 0.1287\n",
            "Epoch 21/30\n",
            "4348/4348 [==============================] - 196s 45ms/step - loss: 3.8889 - accuracy: 0.1473 - val_loss: 4.0635 - val_accuracy: 0.1252\n",
            "Epoch 22/30\n",
            "4348/4348 [==============================] - 196s 45ms/step - loss: 3.8726 - accuracy: 0.1490 - val_loss: 4.0201 - val_accuracy: 0.1339\n",
            "Epoch 23/30\n",
            "4348/4348 [==============================] - 196s 45ms/step - loss: 3.8467 - accuracy: 0.1525 - val_loss: 4.0341 - val_accuracy: 0.1310\n",
            "Epoch 24/30\n",
            "4348/4348 [==============================] - 195s 45ms/step - loss: 3.8412 - accuracy: 0.1542 - val_loss: 4.0383 - val_accuracy: 0.1314\n",
            "Epoch 25/30\n",
            "4348/4348 [==============================] - 195s 45ms/step - loss: 3.8251 - accuracy: 0.1538 - val_loss: 3.9574 - val_accuracy: 0.1364\n",
            "Epoch 26/30\n",
            "4348/4348 [==============================] - 195s 45ms/step - loss: 3.8242 - accuracy: 0.1548 - val_loss: 3.9820 - val_accuracy: 0.1364\n",
            "Epoch 27/30\n",
            "4348/4348 [==============================] - 195s 45ms/step - loss: 3.8129 - accuracy: 0.1597 - val_loss: 3.9891 - val_accuracy: 0.1358\n",
            "Epoch 28/30\n",
            "4348/4348 [==============================] - 195s 45ms/step - loss: 3.8021 - accuracy: 0.1601 - val_loss: 4.0033 - val_accuracy: 0.1358\n",
            "Epoch 29/30\n",
            "4348/4348 [==============================] - 195s 45ms/step - loss: 3.7977 - accuracy: 0.1629 - val_loss: 3.9647 - val_accuracy: 0.1395\n",
            "Epoch 30/30\n",
            "4348/4348 [==============================] - 196s 45ms/step - loss: 3.7817 - accuracy: 0.1638 - val_loss: 3.9105 - val_accuracy: 0.1450\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "D0l6kogMuhOt",
        "outputId": "bcc3baea-f24f-4254-a016-874358c315c3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "print(history.history.keys())\n",
        "# Graficamos el accuracy y el loss.\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYMYXG_074L0"
      },
      "source": [
        "Los resultados demuestran que tanto el accuracy como el loss tienen una tendencia correcta, suben y se reducen respectivamente. Sin embargo se pueden observar ciertos comprotamientos que quizás se puedan mejorar con otro tipo de tunning en los parámetros o en las arquitecturas.\r\n",
        "\r\n",
        "Lo primero que se puede observar es que tanto el Accuracy como el Loss, tal y como se mencionó previamente su tendencia es a aumentar y a bajar. Los valores del accuracy tienen a ser bajos, rodeando el 16% con 30 epochs. Se considera que el bajo valor del accuracy se vea afectado por la cantidad de clases que tiene el Dataset.\r\n",
        "\r\n",
        "Lo segundo que se puede observar es que tanto el Accuracy como el Loss, tiene algunos picos que descienden y no se puede ver una linea curvilinea como lo sería la linea del Train. Esto se cree que se debe a los tipos de parámetros que se usaron en el DataAugmentation, quizás con un tunning de parámetros distinta pueda conseguir reducir considerablemente o en su totalidad los picos.\r\n",
        "\r\n",
        "# **Este mismo comportamiento se verá en la siguiente arquitectura que se presenta.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR51eb4n4Zm5"
      },
      "source": [
        "# Implementando Arquitectura AlexNet\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX3Gprig4qjm",
        "outputId": "858775d1-2e73-4b7d-c827-d6e9c55bae7d"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import ZeroPadding2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 8534540867473018067\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14638920512\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 16469653622173978716\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRal2JoI4xP3"
      },
      "source": [
        "# Inicializamos la red convolucional\n",
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(ZeroPadding2D((1,1),input_shape = (64, 64, 3)))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJYb0k2C1v8r"
      },
      "source": [
        "A diferencia de VGG, en este caso con AlexNet tenemos solo dos layers convolucionales en vez de tres antes de cada MaxPooling.\r\n",
        "\r\n",
        "El primer layer de los dos tiene un tamaño de 48 y un kernel de 5x5 con activación de tipo Relu, para el caso del segundo layer se asignó un tamaño de 128 con un kernel de 3x3 y también activación Relu.\r\n",
        "\r\n",
        "El segundo layer solo contempla el mismo antes del MaxPooling, en este caso tiene tamaño 192 con un kernel de 2x2.\r\n",
        "\r\n",
        "Los siguientes dos layers tienen tamaño de 192 y 128 con kernel de 2x2.\r\n",
        "\r\n",
        "Finalmente las dos primeras capas Dense de tamaño 1024 de activación tipo Relu con un dropout de 0,02 y finalmente la última capa con un tamaño de 200 con activación de tipo Softmax."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coNCwFz_45U8"
      },
      "source": [
        "# Convoluciones\n",
        "classifier.add(Conv2D(48, (5, 5), activation = 'relu'))\n",
        "\n",
        "classifier.add(ZeroPadding2D((1,1)))\n",
        "classifier.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
        "\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Convoluciones\n",
        "classifier.add(ZeroPadding2D((1,1)))\n",
        "classifier.add(Conv2D(192, (2, 2), activation = 'relu'))\n",
        "\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Convoluciones\n",
        "classifier.add(ZeroPadding2D((1,1)))\n",
        "classifier.add(Conv2D(192, (2, 2), activation = 'relu'))\n",
        "\n",
        "# Convoluciones\n",
        "classifier.add(ZeroPadding2D((1,1)))\n",
        "classifier.add(Conv2D(128, (2, 2), activation = 'relu'))\n",
        "\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "classifier.add(Flatten())\n",
        "\n",
        "classifier.add(Dense(units = 1024, activation = 'relu'))\n",
        "classifier.add(Dropout(rate=0.20))\n",
        "\n",
        "classifier.add(Dense(units = 1024, activation = 'relu'))\n",
        "classifier.add(Dropout(rate=0.20))\n",
        "\n",
        "classifier.add(Dense(units = 200, activation = 'softmax'))\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rob-0C8p49WZ"
      },
      "source": [
        "# Compilamos la red\n",
        "Adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0, amsgrad=False)\n",
        "classifier.compile(optimizer = Adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3KC4xav3a29"
      },
      "source": [
        "El procesado de imágenes será el mismo que se utilizó con la arquitectura de VGG. Sin embargo el batch size en este caso se asignó uno de tamaño 256."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "id": "kM4AgE9w5AEQ",
        "outputId": "3548d0c7-de7d-4490-a28b-c58d7fd76794"
      },
      "source": [
        "# Ajustamos la red a las imágenes\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True,\n",
        "                                   rotation_range=20,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   brightness_range=(0.2, 0.8)\n",
        "                                   )\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/RNP-DOCTORADO/DataImages/train',\n",
        "                                                    target_size = (64, 64),\n",
        "                                                    batch_size = 256,\n",
        "                                                    class_mode = 'categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/content/RNP-DOCTORADO/DataImages/validation',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 256,\n",
        "                                            class_mode = 'categorical')\n",
        "\n",
        "history = classifier.fit_generator(training_set,\n",
        "                            epochs = 25,\n",
        "                            validation_data = test_set,\n",
        "                            verbose=1)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 100000 images belonging to 200 classes.\n",
            "Found 10000 images belonging to 200 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "391/391 [==============================] - 191s 482ms/step - loss: 5.2169 - accuracy: 0.0102 - val_loss: 4.8340 - val_accuracy: 0.0424\n",
            "Epoch 2/25\n",
            "391/391 [==============================] - 186s 476ms/step - loss: 4.8523 - accuracy: 0.0403 - val_loss: 4.6033 - val_accuracy: 0.0793\n",
            "Epoch 3/25\n",
            "391/391 [==============================] - 186s 476ms/step - loss: 4.5644 - accuracy: 0.0701 - val_loss: 4.3727 - val_accuracy: 0.1039\n",
            "Epoch 4/25\n",
            "391/391 [==============================] - 185s 474ms/step - loss: 4.3732 - accuracy: 0.0953 - val_loss: 4.2515 - val_accuracy: 0.1108\n",
            "Epoch 5/25\n",
            "391/391 [==============================] - 186s 474ms/step - loss: 4.2392 - accuracy: 0.1125 - val_loss: 4.2844 - val_accuracy: 0.1234\n",
            "Epoch 6/25\n",
            "391/391 [==============================] - 186s 475ms/step - loss: 4.1196 - accuracy: 0.1277 - val_loss: 4.0953 - val_accuracy: 0.1449\n",
            "Epoch 7/25\n",
            "391/391 [==============================] - 186s 476ms/step - loss: 4.0109 - accuracy: 0.1408 - val_loss: 4.0668 - val_accuracy: 0.1488\n",
            "Epoch 8/25\n",
            "391/391 [==============================] - 186s 475ms/step - loss: 3.9502 - accuracy: 0.1509 - val_loss: 3.9078 - val_accuracy: 0.1726\n",
            "Epoch 9/25\n",
            "391/391 [==============================] - 186s 475ms/step - loss: 3.8745 - accuracy: 0.1611 - val_loss: 4.1136 - val_accuracy: 0.1533\n",
            "Epoch 10/25\n",
            "391/391 [==============================] - 186s 476ms/step - loss: 3.8135 - accuracy: 0.1710 - val_loss: 4.0797 - val_accuracy: 0.1600\n",
            "Epoch 11/25\n",
            "391/391 [==============================] - 185s 473ms/step - loss: 3.7485 - accuracy: 0.1797 - val_loss: 3.9865 - val_accuracy: 0.1641\n",
            "Epoch 12/25\n",
            "391/391 [==============================] - 185s 473ms/step - loss: 3.7125 - accuracy: 0.1861 - val_loss: 3.9861 - val_accuracy: 0.1724\n",
            "Epoch 13/25\n",
            " 64/391 [===>..........................] - ETA: 2:31 - loss: 3.6591 - accuracy: 0.1957"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-7ac0e05576be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m                             \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                             \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                             verbose=1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rzsfGlZ5DFE"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd-P1Ci83tNr"
      },
      "source": [
        "Los resultados demuestran que tanto el accuracy como el loss tienen una tendencia correcta, suben y se reducen respectivamente. Sin embargo se pueden observar ciertos comprotamientos que quizás se puedan mejorar con otro tipo de tunning en los parámetros o en las arquitecturas.\r\n",
        "\r\n",
        "Lo primero que se puede observar es que tanto el Accuracy como el Loss, tal y como se mencionó previamente su tendencia es a aumentar y a bajar. Los valores del accuracy tienen a ser bajos, rodeando los 25% con 25 epochs. Se considera que el bajo valor del accuracy se vea afectado por la cantidad de clases que tiene el Dataset.\r\n",
        "\r\n",
        "Lo segundo que se puede observar es que tanto el Accuracy como el Loss, tiene algunos picos que descienden y no se puede ver una linea curvilinea como lo sería la linea del Train. Esto se cree que se debe a los tipos de parámetros que se usaron en el DataAugmentation, quizás con un tunning de parámetros distinta pueda conseguir reducir considerablemente o en su totalidad los picos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1f1P4mKnE_b"
      },
      "source": [
        "# Modelo Pre-entrenado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyJlMl6Z5oeV"
      },
      "source": [
        "Para los modelos Pre-entrenados se utilizó el modelo de VGG16, modelo encontrado en Keras: https://keras.io/api/applications/\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfqWhlzhnDuN"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16                                                     \r\n",
        "from keras.applications.inception_resnet_v2 import preprocess_input, decode_predictions\r\n",
        "from keras.preprocessing import image\r\n",
        "from tensorflow.keras.layers import Input\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.optimizers import SGD\r\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\r\n",
        "import numpy as np                      \r\n",
        "\r\n",
        "\r\n",
        "base_model = VGG16(weights='imagenet', include_top=False)\r\n",
        "\r\n",
        "x = base_model.output\r\n",
        "x = GlobalAveragePooling2D()(x)\r\n",
        "x = Dense(1024, activation='relu')(x)\r\n",
        "\r\n",
        "predictions = Dense(200, activation='softmax')(x)\r\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\r\n",
        "\r\n",
        "for layer in base_model.layers:\r\n",
        "    layer.trainable = False\r\n",
        "\r\n",
        "sgd_opt = SGD(lr=0.01, momentum=0.9, decay=0.0, nesterov=True)\r\n",
        "model.compile(optimizer=sgd_opt,\r\n",
        "              loss='categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bcv3Y1qKnzUR"
      },
      "source": [
        "# Ajustamos la red a las imágenes\r\n",
        "import tensorflow as tf\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator(rescale = 1)\r\n",
        "\r\n",
        "test_datagen = ImageDataGenerator(rescale = 1)\r\n",
        "\r\n",
        "training_set = train_datagen.flow_from_directory('/content/RNP-DOCTORADO/DataImages/train',\r\n",
        "                                                 target_size = (64, 64),\r\n",
        "                                                 batch_size = 23,\r\n",
        "                                                 class_mode = 'categorical')\r\n",
        "\r\n",
        "test_set = test_datagen.flow_from_directory('/content/RNP-DOCTORADO/DataImages/validation',\r\n",
        "                                            target_size = (64, 64),\r\n",
        "                                            batch_size = 23,\r\n",
        "                                            class_mode = 'categorical')\r\n",
        "\r\n",
        "\r\n",
        "training_set = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "  '/content/RNP-DOCTORADO/DataImages/train',\r\n",
        "  validation_split=0.2,\r\n",
        "  subset=\"training\",\r\n",
        "  seed=123,\r\n",
        "  image_size=(64, 64),\r\n",
        "  batch_size=23,\r\n",
        "  label_mode='categorical')\r\n",
        "\r\n",
        "test_set = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "  '/content/RNP-DOCTORADO/DataImages/validation',\r\n",
        "  validation_split=0.2,\r\n",
        "  subset=\"validation\",\r\n",
        "  seed=123,\r\n",
        "  image_size=(64, 64),\r\n",
        "  batch_size=23,\r\n",
        "  label_mode='categorical')\r\n",
        "\r\n",
        "\r\n",
        "history = model.fit(training_set,\r\n",
        "                         epochs = 25,\r\n",
        "                         validation_data = test_set,\r\n",
        "                         verbose=1)\r\n",
        "\r\n",
        "\r\n",
        "for i, layer in enumerate(base_model.layers):\r\n",
        "   print(i, layer.name)\r\n",
        "\r\n",
        "# we chose to train the top 2 inception blocks, i.e. we will freeze\r\n",
        "# the first 249 layers and unfreeze the rest:\r\n",
        "for layer in model.layers[:249]:\r\n",
        "   layer.trainable = False\r\n",
        "for layer in model.layers[249:]:\r\n",
        "   layer.trainable = True\r\n",
        "\r\n",
        "# we need to recompile the model for these modifications to take effect\r\n",
        "# we use SGD with a low learning rate\r\n",
        "from tensorflow.keras.optimizers import SGD\r\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')\r\n",
        "\r\n",
        "history = model.fit(training_set,\r\n",
        "                         epochs = 5,\r\n",
        "                         validation_data = test_set,\r\n",
        "                         verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGjvwwgVn5OV"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "hist = history\r\n",
        "print(hist.history.keys())\r\n",
        "# summarize history for accuracy\r\n",
        "#plt.plot(hist.history['categorical_crossentropy'])\r\n",
        "#plt.plot(hist.history['val_accuracy'])\r\n",
        "#plt.title('model accuracy')\r\n",
        "#plt.ylabel('accuracy')\r\n",
        "#plt.xlabel('epoch')\r\n",
        "#plt.legend(['train', 'test'], loc='upper left')\r\n",
        "#plt.show()\r\n",
        "\r\n",
        "plt.plot(hist.history['loss'])\r\n",
        "plt.plot(hist.history['val_loss'])\r\n",
        "plt.title('model loss')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.legend(['train', 'test'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjtISFJE7H5c"
      },
      "source": [
        "Como se puede observar los valores de Train y Test se mantienen estáticos en 5,277 y 5,270 respectivamente. Se cree que esto se puede deber a que al preprocesado de las imágenes y del modelo pre-entrado se consigue a llegar al punto mínimo o llamemoslo \"valle\" en un descenso del gradiente que es muy difícil salir."
      ]
    }
  ]
}